{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 384, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from basenet.vgg16_bn import vgg16_bn, init_weights\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch + mid_ch, mid_ch, kernel_size=1),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class CRAFT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRAFT, self).__init__()\n",
    "        self.basenet = vgg16_bn(pretrained=False, freeze=False)\n",
    "        self.upconv1 = double_conv(1024, 512, 256)\n",
    "        self.upconv2 = double_conv(512, 256, 128)\n",
    "        self.upconv3 = double_conv(256, 128, 64)\n",
    "        self.upconv4 = double_conv(128, 64, 32)\n",
    "\n",
    "        self.conv_cls = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 2, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        init_weights(self.upconv1.modules())\n",
    "        init_weights(self.upconv2.modules())\n",
    "        init_weights(self.upconv3.modules())\n",
    "        init_weights(self.upconv4.modules())\n",
    "        init_weights(self.conv_cls.modules())\n",
    "\n",
    "    def forward(self, x):\n",
    "        sources = self.basenet(x)\n",
    "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
    "        y = self.upconv1(y)\n",
    "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[2]], dim=1)\n",
    "        y = self.upconv2(y)\n",
    "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[3]], dim=1)\n",
    "        y = self.upconv3(y)\n",
    "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[4]], dim=1)\n",
    "        feature = self.upconv4(y)\n",
    "        y = self.conv_cls(feature)\n",
    "        return y.permute(0, 2, 3, 1), feature\n",
    "\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = torch.load(weight_path, map_location='cpu')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] if k.startswith(\"module.\") else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = CRAFT()\n",
    "    weight_path = \"craft_mlt_25k.pth\"\n",
    "    load_weights(model, weight_path)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    output, _ = model(torch.randn(1, 3, 768, 768).cuda())\n",
    "    print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built\n",
      "for\n",
      "all\n",
      "delivery\n",
      "fleets.\n",
      "9:19\n",
      "78%\n",
      "Whether\n",
      "fleet\n",
      "of\n",
      "small\n",
      "you\n",
      "manage\n",
      "a\n",
      "delivery\n",
      "vehicles\n",
      "large\n",
      "of\n",
      "network\n",
      "0.2\n",
      "or\n",
      "a\n",
      "aall\n",
      "E\n",
      "36th\n",
      "drivers,\n",
      "NavaFLEET\n",
      "Solution\n",
      "scales\n",
      "our\n",
      "to\n",
      "needs.\n",
      "your\n",
      "Then\n",
      "Park\n",
      "Ave\n",
      "Ss\n",
      "fleet\n",
      "in\n",
      "real-time\n",
      "Track\n",
      "your\n",
      "See\n",
      "exact\n",
      "locations\n",
      "and\n",
      "get\n",
      "—)\n",
      "\n",
      "NEXT\n",
      "z\n",
      "sg\n",
      "z\n",
      "minute-by-minute\n",
      "updates\n",
      "with\n",
      "\n",
      "tu\n",
      "Google\n",
      "Maps.\n",
      "=\n",
      "z\n",
      "s\n",
      "5\n",
      "2\n",
      "Set\n",
      "boundaries\n",
      "and\n",
      "get\n",
      "alerts\n",
      "w\n",
      "notifi\n",
      "for\n",
      "Receive\n",
      "cations\n",
      "f=\n",
      "S\n",
      "2\n",
      "3\n",
      "‘SI\n",
      "unauthorized\n",
      "movements,\n",
      "deviations,\n",
      "and\n",
      "route\n",
      "more\n",
      "Analyze\n",
      "driver\n",
      "behavior.\n",
      "v\n",
      "2\n",
      ">\n",
      "Monitor\n",
      "speed,\n",
      "braking,\n",
      "and\n",
      "idling\n",
      "improve\n",
      "safety\n",
      "and\n",
      "to\n",
      "performance\n",
      "3\n",
      "minutes\n",
      "Optimize\n",
      "and\n",
      "routes\n",
      "Save\n",
      "0.8\n",
      "mi\n",
      "8:52\n",
      "PM\n",
      "fuel.\n",
      "Reduce\n",
      "costs\n",
      "with\n",
      "smarter,\n",
      "efficient\n",
      "routes.\n",
      "more\n",
      "Drop-off\n",
      "package\n",
      "NavaFleet\n",
      "leverages\n",
      "Maps\n",
      "for\n",
      "Google\n",
      "425\n",
      "Charleston\n",
      "Rd\n",
      "precise\n",
      "fleet\n",
      "visibility\n",
      "and\n",
      "operational\n",
      "efficiency.\n",
      "user-friendly,\n",
      "Its\n",
      "scalable\n",
      "interface\n",
      "requires\n",
      "minima\n",
      "\n",
      "training.\n",
      "Customize\n",
      "and\n",
      "alerts,\n",
      "reports,\n",
      "dashboards\n",
      "suit\n",
      "operations.\n",
      "to\n",
      "your\n",
      "reducing\n",
      "improving\n",
      "safety,\n",
      "and\n",
      "costs,\n",
      "enhancing\n",
      "delivery\n",
      "efficiency.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from basenet.vgg16_bn import vgg16_bn, init_weights\n",
    "import imgproc\n",
    "import craft_utils\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch+mid_ch, mid_ch, kernel_size=1),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class CRAFT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRAFT, self).__init__()\n",
    "        self.basenet = vgg16_bn(pretrained=False, freeze=False)\n",
    "        self.upconv1 = double_conv(1024, 512, 256)\n",
    "        self.upconv2 = double_conv(512, 256, 128)\n",
    "        self.upconv3 = double_conv(256, 128, 64)\n",
    "        self.upconv4 = double_conv(128, 64, 32)\n",
    "        self.conv_cls = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 2, kernel_size=1)\n",
    "        )\n",
    "        init_weights(self.upconv1.modules())\n",
    "        init_weights(self.upconv2.modules())\n",
    "        init_weights(self.upconv3.modules())\n",
    "        init_weights(self.upconv4.modules())\n",
    "        init_weights(self.conv_cls.modules())\n",
    "    def forward(self, x):\n",
    "        sources = self.basenet(x)\n",
    "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
    "        y = self.upconv1(y)\n",
    "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[2]], dim=1)\n",
    "        y = self.upconv2(y)\n",
    "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[3]], dim=1)\n",
    "        y = self.upconv3(y)\n",
    "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[4]], dim=1)\n",
    "        feature = self.upconv4(y)\n",
    "        y = self.conv_cls(feature)\n",
    "        return y.permute(0,2,3,1), feature\n",
    "\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = torch.load(weight_path, map_location='cpu')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] if k.startswith(\"module.\") else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    model = CRAFT()\n",
    "    load_weights(model, \"craft_mlt_25k.pth\")\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    image = cv2.imread(\"img_test_ocr.png\")\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
    "    ratio_h = ratio_w = 1/target_ratio\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2,0,1).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(x)\n",
    "    score_text = output[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = output[0,:,:,1].cpu().data.numpy()\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, 0.7, 0.4, 0.4, False)\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    img_out = image.copy()\n",
    "    for box in boxes:\n",
    "        box_np = np.array(box, dtype=np.int32).reshape((-1,1,2))\n",
    "        cv2.polylines(img_out, [box_np], True, (0,255,0), 2)\n",
    "        x_min = int(box_np[:,0,0].min())\n",
    "        y_min = int(box_np[:,0,1].min())\n",
    "        x_max = int(box_np[:,0,0].max())\n",
    "        y_max = int(box_np[:,0,1].max())\n",
    "        roi = image[y_min:y_max, x_min:x_max]\n",
    "        txt = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built :  (348, 10, 52, 16)\n",
      "Tor :  (407, 10, 32, 16)\n",
      "delivery :  (480, 8, 91, 23)\n",
      "fleets. :  (577, 9, 69, 17)\n",
      "9:19 :  (30, 27, 23, 9)\n",
      "78% :  (260, 28, 24, 9)\n",
      "Whether :  (347, 53, 64, 12)\n",
      "fleet! :  (571, 53, 32, 12)\n",
      "lof :  (608, 53, 15, 12)\n",
      "small :  (526, 54, 38, 11)\n",
      "YOu :  (415, 56, 26, 12)\n",
      "manage :  (448, 56, 60, 12)\n",
      "id :  (513, 56, 7, 9)\n",
      "delivery, :  (347, 72, 58, 16)\n",
      "Vehicles :  (410, 72, 58, 12)\n",
      "large :  (508, 72, 36, 16)\n",
      "i :  (615, 72, 14, 12)\n",
      "nerwork :  (550, 74, 59, 10)\n",
      "0.2 :  (70, 74, 45, 23)\n",
      "ai :  (474, 75, 14, 9)\n",
      "S :  (495, 76, 5, 8)\n",
      "fall :  (126, 82, 19, 15)\n",
      "E :  (232, 83, 9, 13)\n",
      "36th :  (246, 84, 36, 12)\n",
      "drivers, :  (347, 88, 56, 17)\n",
      "NavaFLeEeE :  (439, 92, 82, 12)\n",
      "Tl :  (512, 90, 10, 15)\n",
      "Solution :  (528, 92, 63, 12)\n",
      "scales :  (598, 92, 43, 12)\n",
      "oun :  (407, 95, 25, 9)\n",
      "ite :  (646, 94, 14, 10)\n",
      "Needs. :  (386, 111, 43, 12)\n",
      "YOU :  (346, 114, 34, 13)\n",
      "Then :  (31, 131, 34, 12)\n",
      "Park :  (97, 131, 31, 12)\n",
      "Ave :  (134, 131, 25, 12)\n",
      "Ss :  (163, 131, 8, 12)\n",
      "fleet :  (474, 150, 35, 12)\n",
      "in :  (515, 150, 13, 12)\n",
      "real-time :  (535, 150, 71, 12)\n",
      "Track :  (386, 151, 42, 11)\n",
      "your :  (433, 153, 35, 12)\n",
      "See :  (386, 170, 25, 11)\n",
      "Py :  (418, 172, 12, 9)\n",
      "ach :  (434, 170, 21, 11)\n",
      "locations :  (461, 170, 64, 11)\n",
      "and :  (532, 170, 26, 11)\n",
      "iget} :  (565, 170, 23, 15)\n",
      "NEXT :  (44, 185, 36, 13)\n",
      "iS] :  (264, 189, 11, 8)\n",
      "I :  (265, 198, 10, 12)\n",
      "& :  (266, 211, 10, 8)\n",
      "minute-by-minute :  (387, 189, 132, 15)\n",
      "lupdates :  (525, 189, 59, 15)\n",
      "with :  (590, 189, 30, 12)\n",
      "Google :  (387, 208, 51, 15)\n",
      "Maps, :  (445, 208, 42, 15)\n",
      "iz :  (268, 224, 11, 16)\n",
      "| :  (271, 241, 8, 7)\n",
      "> :  (170, 243, 10, 26)\n",
      "Set :  (386, 247, 23, 11)\n",
      "boundaries :  (416, 246, 88, 12)\n",
      "and :  (510, 246, 27, 12)\n",
      "iget :  (544, 247, 25, 15)\n",
      "alerts) :  (574, 247, 45, 11)\n",
      "te :  (272, 252, 11, 9)\n",
      "Motiti :  (448, 264, 35, 13)\n",
      "Ton :  (543, 265, 21, 12)\n",
      "Receive :  (387, 266, 54, 11)\n",
      "rations :  (487, 266, 50, 11)\n",
      "fe :  (170, 272, 10, 12)\n",
      "2 :  (171, 285, 9, 21)\n",
      "< :  (170, 308, 10, 9)\n",
      "S :  (171, 318, 9, 7)\n",
      "“unauthorized :  (386, 284, 98, 13)\n",
      "movements, :  (491, 286, 90, 11)\n",
      "deviations; :  (431, 303, 78, 14)\n",
      "and :  (515, 304, 26, 12)\n",
      "route :  (387, 304, 38, 12)\n",
      "more :  (550, 307, 36, 9)\n",
      "‘Analyze :  (385, 342, 62, 14)\n",
      "driver :  (452, 342, 47, 11)\n",
      "behavior. :  (505, 342, 71, 12)\n",
      "ro :  (286, 354, 13, 10)\n",
      "2 :  (287, 366, 12, 15)\n",
      "= :  (289, 382, 11, 7)\n",
      "Monitor :  (387, 361, 57, 12)\n",
      "Speed, :  (450, 362, 47, 13)\n",
      "Draking, :  (504, 362, 59, 14)\n",
      "and :  (570, 362, 26, 11)\n",
      "idling :  (386, 380, 40, 16)\n",
      "‘improve :  (452, 383, 59, 12)\n",
      "isafety; :  (517, 376, 45, 19)\n",
      "anc :  (566, 380, 27, 12)\n",
      "TO :  (432, 382, 13, 10)\n",
      "performance :  (386, 394, 96, 21)\n",
      "3) :  (31, 420, 9, 13)\n",
      "inutes| :  (63, 421, 50, 13)\n",
      "Optimize :  (387, 438, 69, 15)\n",
      "and :  (518, 438, 27, 11)\n",
      "routes :  (463, 439, 49, 10)\n",
      "save :  (552, 441, 35, 8)\n",
      "1) :  (28, 440, 9, 13)\n",
      "eI :  (42, 440, 8, 13)\n",
      "i :  (54, 444, 14, 8)\n",
      "PSA :  (82, 442, 26, 10)\n",
      "on :  (114, 442, 19, 10)\n",
      "fuel, :  (386, 457, 34, 12)\n",
      "Reduce :  (426, 457, 53, 12)\n",
      "costs :  (485, 458, 36, 11)\n",
      "WITT) :  (528, 458, 29, 11)\n",
      "smarter, :  (564, 458, 58, 13)\n",
      "efficient! :  (430, 476, 59, 12)\n",
      "routes) :  (495, 477, 50, 11)\n",
      "more :  (387, 479, 37, 9)\n",
      "Drop-off :  (90, 495, 65, 13)\n",
      "package :  (159, 495, 63, 15)\n",
      "NavaFieet :  (348, 502, 78, 12)\n",
      "leverages :  (433, 502, 69, 15)\n",
      "Maps) :  (567, 502, 38, 14)\n",
      "ifels :  (610, 502, 21, 11)\n",
      "Google :  (508, 503, 52, 14)\n",
      "A425 :  (98, 515, 22, 10)\n",
      "‘Charleston :  (124, 515, 70, 11)\n",
      "Rd :  (199, 515, 15, 10)\n",
      "precise :  (348, 521, 51, 15)\n",
      "fleet :  (404, 520, 33, 13)\n",
      "Visibility, :  (442, 516, 61, 21)\n",
      "and :  (506, 522, 26, 11)\n",
      "loperational :  (539, 521, 84, 15)\n",
      "efficiency, :  (347, 539, 72, 17)\n",
      "user-friendly, :  (448, 535, 99, 20)\n",
      "Its :  (425, 540, 18, 12)\n",
      "scalable :  (551, 540, 58, 12)\n",
      "interface :  (348, 559, 64, 12)\n",
      "requires :  (418, 562, 59, 10)\n",
      "minima :  (484, 559, 53, 13)\n",
      "training, :  (548, 559, 57, 16)\n",
      "Customize :  (347, 578, 77, 12)\n",
      "and :  (543, 578, 26, 12)\n",
      "alerts, :  (430, 578, 44, 14)\n",
      "reports, :  (481, 579, 56, 13)\n",
      "dashboards :  (347, 598, 87, 12)\n",
      "Suit :  (459, 598, 26, 12)\n",
      "pperations: :  (529, 598, 79, 14)\n",
      "TO :  (439, 599, 14, 10)\n",
      "VOUr :  (490, 601, 34, 12)\n",
      "reducing :  (348, 617, 63, 16)\n",
      "improving :  (465, 617, 73, 16)\n",
      "safety, :  (545, 612, 50, 21)\n",
      "and :  (598, 617, 26, 12)\n",
      "costs) :  (418, 618, 40, 13)\n",
      "lenhancing| :  (347, 631, 80, 21)\n",
      "delivery, :  (430, 631, 60, 21)\n",
      "lefticiency, :  (492, 631, 76, 21)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from basenet.vgg16_bn import vgg16_bn, init_weights\n",
    "import imgproc\n",
    "import craft_utils\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch+mid_ch, mid_ch, kernel_size=1),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class CRAFT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRAFT, self).__init__()\n",
    "        self.basenet = vgg16_bn(pretrained=False, freeze=False)\n",
    "        self.upconv1 = double_conv(1024, 512, 256)\n",
    "        self.upconv2 = double_conv(512, 256, 128)\n",
    "        self.upconv3 = double_conv(256, 128, 64)\n",
    "        self.upconv4 = double_conv(128, 64, 32)\n",
    "        self.conv_cls = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 2, kernel_size=1)\n",
    "        )\n",
    "        init_weights(self.upconv1.modules())\n",
    "        init_weights(self.upconv2.modules())\n",
    "        init_weights(self.upconv3.modules())\n",
    "        init_weights(self.upconv4.modules())\n",
    "        init_weights(self.conv_cls.modules())\n",
    "    def forward(self, x):\n",
    "        sources = self.basenet(x)\n",
    "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
    "        y = self.upconv1(y)\n",
    "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[2]], dim=1)\n",
    "        y = self.upconv2(y)\n",
    "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[3]], dim=1)\n",
    "        y = self.upconv3(y)\n",
    "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[4]], dim=1)\n",
    "        feature = self.upconv4(y)\n",
    "        y = self.conv_cls(feature)\n",
    "        return y.permute(0,2,3,1), feature\n",
    "\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = torch.load(weight_path, map_location='cpu')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] if k.startswith(\"module.\") else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    model = CRAFT()\n",
    "    load_weights(model, \"craft_mlt_25k.pth\")\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    image = cv2.imread(\"img_test_ocr.png\")\n",
    "    orig_image = image.copy()\n",
    "    img_resized, target_ratio, _ = imgproc.resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
    "    ratio_h = ratio_w = 1/target_ratio\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2,0,1).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(x)\n",
    "    score_text = output[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = output[0,:,:,1].cpu().data.numpy()\n",
    "    boxes, _ = craft_utils.getDetBoxes(score_text, score_link, 0.7, 0.4, 0.4, False)\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    for box in boxes:\n",
    "        box_np = np.array(box, dtype=np.int32).reshape((-1,1,2))\n",
    "        cv2.polylines(orig_image, [box_np], True, (0,255,0), 2)\n",
    "        x_min = int(box_np[:,0,0].min())\n",
    "        y_min = int(box_np[:,0,1].min())\n",
    "        x_max = int(box_np[:,0,0].max())\n",
    "        y_max = int(box_np[:,0,1].max())\n",
    "        roi = orig_image[y_min:y_max, x_min:x_max]\n",
    "        data = pytesseract.image_to_data(roi, config=\"--psm 6\", output_type=pytesseract.Output.DICT)\n",
    "        n_words = len(data['text'])\n",
    "        for i in range(n_words):\n",
    "            if data['text'][i].strip() != \"\":\n",
    "                word = data['text'][i].strip()\n",
    "                w_x = int(data['left'][i]) + x_min\n",
    "                w_y = int(data['top'][i]) + y_min\n",
    "                w_w = int(data['width'][i])\n",
    "                w_h = int(data['height'][i])\n",
    "                cv2.rectangle(orig_image, (w_x, w_y), (w_x+w_w, w_y+w_h), (255,0,0), 1)\n",
    "                print(word, \": \", (w_x, w_y, w_w, w_h))\n",
    "    cv2.imshow(\"Result\", orig_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'delivery', 'x': 477, 'y': 5, 'w': 95, 'h': 28, 'color': array([112.72907154,  69.91171994,  25.60273973])}, {'text': 'fleets.', 'x': 574, 'y': 7, 'w': 74, 'h': 22, 'color': array([112.21560575,  69.93634497,  27.45995893])}, {'text': 'Built', 'x': 346, 'y': 8, 'w': 56, 'h': 20, 'color': array([114.4787472 ,  73.42058166,  32.87695749])}, {'text': 'for', 'x': 405, 'y': 8, 'w': 36, 'h': 20, 'color': array([112.13362069,  69.33189655,  25.5862069 ])}, {'text': 'all', 'x': 445, 'y': 8, 'w': 29, 'h': 20, 'color': array([123.04132231,  81.52066116,  37.99586777])}, {'text': '9:19', 'x': 28, 'y': 25, 'w': 26, 'h': 12, 'color': array([106.01834862,  64.05504587,  18.21100917])}]\n",
      "[{'text': '78%', 'x': 258, 'y': 25, 'w': 27, 'h': 13, 'color': array([107.71428571,  66.2244898 ,  20.90204082])}]\n",
      "[{'text': 'Whether', 'x': 345, 'y': 50, 'w': 67, 'h': 16, 'color': array([112.31274131, 109.27799228, 110.28957529])}]\n",
      "[{'text': 'fleet', 'x': 568, 'y': 50, 'w': 36, 'h': 16, 'color': array([98.77391304, 93.87826087, 93.73043478])}, {'text': 'of', 'x': 605, 'y': 50, 'w': 19, 'h': 16, 'color': array([112.43939394, 108.62121212, 114.75757576])}, {'text': 'small', 'x': 524, 'y': 52, 'w': 42, 'h': 14, 'color': array([105.0620155 ,  98.55813953,  97.6744186 ])}, {'text': 'you', 'x': 413, 'y': 53, 'w': 29, 'h': 16, 'color': array([109.50485437, 106.41747573, 112.00970874])}, {'text': 'manage', 'x': 446, 'y': 53, 'w': 63, 'h': 16, 'color': array([111.74025974, 108.38961039, 108.08225108])}, {'text': 'a', 'x': 510, 'y': 54, 'w': 11, 'h': 12, 'color': array([ 96.46666667,  96.53333333, 100.33333333])}, {'text': 'delivery', 'x': 344, 'y': 69, 'w': 63, 'h': 20, 'color': array([107.9086758 , 101.42465753, 103.36986301])}, {'text': 'vehicles', 'x': 408, 'y': 70, 'w': 61, 'h': 15, 'color': array([108.20853081, 102.8957346 , 104.60189573])}]\n",
      "[{'text': 'large', 'x': 503, 'y': 70, 'w': 43, 'h': 20, 'color': array([101.93333333,  95.2962963 ,  95.08888889])}]\n",
      "[{'text': 'of', 'x': 613, 'y': 70, 'w': 17, 'h': 15, 'color': array([100.24,  95.18,  94.28])}, {'text': '0.2', 'x': 68, 'y': 72, 'w': 49, 'h': 26, 'color': array([72.36674528, 72.36674528, 72.36674528])}]\n",
      "[{'text': 'network', 'x': 548, 'y': 72, 'w': 62, 'h': 13, 'color': array([108.85840708, 106.01327434, 108.54424779])}, {'text': 'or', 'x': 472, 'y': 73, 'w': 17, 'h': 12, 'color': array([104.82608696,  96.58695652,  94.        ])}, {'text': 'a', 'x': 493, 'y': 74, 'w': 8, 'h': 11, 'color': array([115.38888889, 110.11111111, 107.11111111])}, {'text': 'aall', 'x': 124, 'y': 80, 'w': 24, 'h': 18, 'color': array([71.43653251, 71.43653251, 71.43653251])}]\n",
      "[{'text': 'E', 'x': 230, 'y': 81, 'w': 12, 'h': 16, 'color': array([75.64661654, 75.64661654, 75.64661654])}, {'text': '36th', 'x': 244, 'y': 82, 'w': 40, 'h': 16, 'color': array([75.32142857, 75.32142857, 75.32142857])}]\n",
      "[{'text': 'drivers,', 'x': 345, 'y': 88, 'w': 58, 'h': 18, 'color': array([107.39784946, 102.33333333, 104.20967742])}]\n",
      "[{'text': 'NavaFLEET', 'x': 437, 'y': 90, 'w': 85, 'h': 15, 'color': array([84.39503386, 82.2731377 , 83.43340858])}, {'text': 'Solution', 'x': 525, 'y': 90, 'w': 67, 'h': 15, 'color': array([90.14067278, 87.17737003, 87.81039755])}, {'text': 'scales', 'x': 596, 'y': 90, 'w': 46, 'h': 15, 'color': array([108.13580247, 105.41358025, 106.45061728])}, {'text': 'our', 'x': 405, 'y': 92, 'w': 28, 'h': 13, 'color': array([112.61052632, 109.2       , 114.55789474])}]\n",
      "[{'text': 'to', 'x': 644, 'y': 92, 'w': 17, 'h': 13, 'color': array([97.95918367, 93.30612245, 92.83673469])}, {'text': 'needs.', 'x': 383, 'y': 108, 'w': 51, 'h': 17, 'color': array([112.66285714, 107.14285714, 105.41714286])}, {'text': 'your', 'x': 344, 'y': 112, 'w': 37, 'h': 16, 'color': array([111.23770492, 106.13934426, 110.47540984])}, {'text': 'Then', 'x': 29, 'y': 129, 'w': 37, 'h': 15, 'color': array([107.96437659, 107.96437659, 107.96437659])}]\n",
      "[{'text': 'Park', 'x': 94, 'y': 129, 'w': 35, 'h': 15, 'color': array([108.76358696, 108.76358696, 108.76358696])}, {'text': 'Ave', 'x': 132, 'y': 129, 'w': 28, 'h': 15, 'color': array([108.91919192, 108.91919192, 108.91919192])}, {'text': 'Ss', 'x': 161, 'y': 129, 'w': 11, 'h': 15, 'color': array([108.76923077, 108.76923077, 108.76923077])}]\n",
      "[{'text': 'fleet', 'x': 471, 'y': 147, 'w': 40, 'h': 18, 'color': array([90.475, 90.12 , 92.015])}, {'text': 'in', 'x': 513, 'y': 148, 'w': 16, 'h': 16, 'color': array([97.90123457, 94.88888889, 97.49382716])}, {'text': 'real-time', 'x': 532, 'y': 148, 'w': 76, 'h': 16, 'color': array([91.78529412, 89.78823529, 90.32352941])}, {'text': 'Track', 'x': 384, 'y': 149, 'w': 45, 'h': 15, 'color': array([86.55263158, 82.28421053, 82.34210526])}, {'text': 'your', 'x': 430, 'y': 150, 'w': 39, 'h': 16, 'color': array([94.08695652, 90.9076087 , 92.70652174])}]\n",
      "[{'text': 'get', 'x': 561, 'y': 167, 'w': 30, 'h': 20, 'color': array([109.57142857, 104.52380952, 104.43809524])}, {'text': 'See', 'x': 384, 'y': 168, 'w': 28, 'h': 14, 'color': array([100.35051546,  95.82474227,  96.75257732])}, {'text': 'exact', 'x': 416, 'y': 168, 'w': 40, 'h': 14, 'color': array([106.59859155, 103.11971831, 104.30985915])}, {'text': 'locations', 'x': 458, 'y': 168, 'w': 68, 'h': 14, 'color': array([113.54365079, 109.76587302, 109.68253968])}, {'text': 'and', 'x': 530, 'y': 168, 'w': 30, 'h': 14, 'color': array([93.6741573 , 89.47191011, 91.91011236])}, {'text': '—)', 'x': 172, 'y': 177, 'w': 8, 'h': 7, 'color': array([95.59090909, 88.36363636, 82.90909091])}]\n",
      "[{'text': 'updates', 'x': 521, 'y': 184, 'w': 65, 'h': 22, 'color': array([110.47876448, 109.76447876, 114.8957529 ])}, {'text': 'NEXT', 'x': 44, 'y': 185, 'w': 36, 'h': 13, 'color': array([172.57632399, 170.89719626, 168.7165109 ])}]\n",
      "[{'text': 'z\\nsg\\nz', 'x': 261, 'y': 186, 'w': 16, 'h': 34, 'color': array([113.72932331, 109.7518797 , 105.87218045])}]\n",
      "[{'text': 'minute-by-minute', 'x': 385, 'y': 186, 'w': 135, 'h': 19, 'color': array([108.29220779, 104.01515152, 106.6991342 ])}]\n",
      "[{'text': 'with', 'x': 588, 'y': 186, 'w': 34, 'h': 18, 'color': array([109.37190083, 100.80991736, 102.28099174])}, {'text': 'tu', 'x': 170, 'y': 205, 'w': 10, 'h': 7, 'color': array([128.62857143, 113.97142857,  97.4       ])}]\n",
      "[{'text': 'Maps.', 'x': 443, 'y': 205, 'w': 47, 'h': 20, 'color': array([110.91017964, 103.65868263, 101.16167665])}, {'text': 'Google', 'x': 385, 'y': 206, 'w': 55, 'h': 19, 'color': array([116.75527426, 110.33333333, 109.66244726])}, {'text': '=', 'x': 168, 'y': 212, 'w': 10, 'h': 12, 'color': array([127.94827586, 108.27586207,  85.86206897])}]\n",
      "[{'text': 'z\\ns', 'x': 265, 'y': 220, 'w': 16, 'h': 30, 'color': array([120.01754386, 116.03508772, 111.8245614 ])}]\n",
      "[{'text': '5\\n2', 'x': 168, 'y': 241, 'w': 13, 'h': 29, 'color': array([148.90697674, 109.64534884,  71.23837209])}]\n",
      "[{'text': 'Set', 'x': 384, 'y': 244, 'w': 26, 'h': 16, 'color': array([90.50746269, 86.82089552, 86.76865672])}, {'text': 'boundaries', 'x': 414, 'y': 244, 'w': 91, 'h': 16, 'color': array([89.99782609, 88.26304348, 90.56956522])}, {'text': 'and', 'x': 508, 'y': 244, 'w': 30, 'h': 16, 'color': array([95.33986928, 87.94117647, 85.46405229])}, {'text': 'get', 'x': 540, 'y': 244, 'w': 31, 'h': 19, 'color': array([90.44370861, 85.89403974, 85.37748344])}, {'text': 'alerts', 'x': 572, 'y': 245, 'w': 49, 'h': 15, 'color': array([92.71729958, 90.01687764, 91.69620253])}, {'text': 'w', 'x': 270, 'y': 250, 'w': 14, 'h': 12, 'color': array([117.02083333, 112.77083333, 107.83333333])}]\n",
      "[{'text': 'notifi', 'x': 444, 'y': 261, 'w': 42, 'h': 19, 'color': array([101.41085271,  96.97674419, 100.17054264])}]\n",
      "[{'text': 'for', 'x': 541, 'y': 262, 'w': 24, 'h': 16, 'color': array([114.10227273, 110.10227273, 112.95454545])}, {'text': 'Receive', 'x': 385, 'y': 264, 'w': 57, 'h': 14, 'color': array([101.61,  97.16,  98.64])}]\n",
      "[{'text': 'cations', 'x': 484, 'y': 264, 'w': 54, 'h': 14, 'color': array([100.79885057,  98.55172414, 102.85057471])}, {'text': 'f=\\nS\\n2\\n3\\n‘SI', 'x': 168, 'y': 270, 'w': 13, 'h': 56, 'color': array([162.6840796 , 118.99502488,  67.34328358])}]\n",
      "[{'text': 'unauthorized', 'x': 384, 'y': 282, 'w': 101, 'h': 16, 'color': array([114.55053191, 110.29255319, 113.40425532])}, {'text': 'movements,', 'x': 489, 'y': 284, 'w': 93, 'h': 14, 'color': array([109.96078431, 105.86928105, 107.5       ])}, {'text': 'deviations,', 'x': 429, 'y': 300, 'w': 81, 'h': 18, 'color': array([106.65530303, 103.36363636, 105.80681818])}, {'text': 'and', 'x': 513, 'y': 301, 'w': 29, 'h': 16, 'color': array([111.51304348, 112.03478261, 118.70434783])}, {'text': 'route', 'x': 384, 'y': 302, 'w': 42, 'h': 15, 'color': array([110.42335766, 107.74452555, 109.64963504])}]\n",
      "[{'text': 'more', 'x': 548, 'y': 304, 'w': 40, 'h': 13, 'color': array([109.5037037 , 109.28148148, 112.46666667])}]\n",
      "[{'text': 'Analyze', 'x': 383, 'y': 339, 'w': 65, 'h': 19, 'color': array([93.41982507, 91.48104956, 93.99708455])}, {'text': 'driver', 'x': 450, 'y': 340, 'w': 50, 'h': 14, 'color': array([86.80454545, 84.00909091, 85.15909091])}, {'text': 'behavior.', 'x': 502, 'y': 340, 'w': 75, 'h': 16, 'color': array([87.97206704, 85.72067039, 88.12569832])}, {'text': 'v\\n2\\n>', 'x': 284, 'y': 351, 'w': 17, 'h': 40, 'color': array([115.9119171 , 112.30051813, 108.64248705])}]\n",
      "[{'text': 'Monitor', 'x': 385, 'y': 358, 'w': 60, 'h': 16, 'color': array([102.08,  97.14,  98.67])}, {'text': 'speed,', 'x': 448, 'y': 360, 'w': 50, 'h': 16, 'color': array([102.84615385,  99.68639053, 101.15976331])}, {'text': 'braking,', 'x': 502, 'y': 360, 'w': 63, 'h': 17, 'color': array([113.12653061, 108.66938776, 110.84081633])}, {'text': 'and', 'x': 568, 'y': 360, 'w': 29, 'h': 14, 'color': array([110.05555556, 104.30555556, 104.88888889])}, {'text': 'safety', 'x': 513, 'y': 376, 'w': 49, 'h': 20, 'color': array([109.34090909, 106.20454545, 107.57386364])}, {'text': 'idling', 'x': 382, 'y': 378, 'w': 46, 'h': 20, 'color': array([111.72580645, 108.40860215, 115.66666667])}]\n",
      "[{'text': 'improve', 'x': 448, 'y': 378, 'w': 64, 'h': 19, 'color': array([106.90384615, 103.01442308, 104.66346154])}]\n",
      "[{'text': 'and', 'x': 563, 'y': 378, 'w': 31, 'h': 17, 'color': array([123.72440945, 120.56692913, 120.81889764])}, {'text': 'to', 'x': 429, 'y': 380, 'w': 17, 'h': 13, 'color': array([107.25454545, 107.43636364, 110.61818182])}, {'text': 'performance', 'x': 383, 'y': 394, 'w': 101, 'h': 22, 'color': array([111.64325843, 105.99719101, 106.71348315])}]\n",
      "[{'text': '3', 'x': 29, 'y': 418, 'w': 12, 'h': 16, 'color': array([140.10144928, 163.86956522, 101.17391304])}, {'text': 'minutes', 'x': 44, 'y': 418, 'w': 72, 'h': 19, 'color': array([149.37209302, 171.29900332, 113.72093023])}]\n",
      "[{'text': 'Optimize', 'x': 385, 'y': 436, 'w': 73, 'h': 18, 'color': array([89.33159269, 87.34464752, 89.91383812])}]\n",
      "[{'text': 'and', 'x': 516, 'y': 436, 'w': 30, 'h': 14, 'color': array([87.83660131, 85.01960784, 85.37908497])}, {'text': 'routes', 'x': 460, 'y': 437, 'w': 53, 'h': 13, 'color': array([92.19341564, 88.97942387, 88.67901235])}]\n",
      "[{'text': 'Save', 'x': 549, 'y': 438, 'w': 39, 'h': 12, 'color': array([95.20765027, 92.27322404, 93.14754098])}, {'text': '0.8', 'x': 28, 'y': 440, 'w': 22, 'h': 13, 'color': array([174.7027027, 174.7027027, 174.7027027])}, {'text': 'mi', 'x': 52, 'y': 440, 'w': 18, 'h': 13, 'color': array([178.47272727, 178.47272727, 178.47272727])}, {'text': '8:52', 'x': 80, 'y': 440, 'w': 29, 'h': 13, 'color': array([173.98019802, 173.98019802, 173.98019802])}, {'text': 'PM', 'x': 112, 'y': 440, 'w': 22, 'h': 13, 'color': array([164.89189189, 164.89189189, 164.89189189])}]\n",
      "[{'text': 'fuel.', 'x': 383, 'y': 454, 'w': 39, 'h': 17, 'color': array([86.44720497, 84.83850932, 85.88198758])}, {'text': 'Reduce', 'x': 424, 'y': 454, 'w': 56, 'h': 16, 'color': array([112.65652174, 106.96956522, 108.1826087 ])}]\n",
      "[{'text': 'smarter,', 'x': 561, 'y': 454, 'w': 63, 'h': 18, 'color': array([110.30952381, 105.32380952, 104.32857143])}, {'text': 'costs', 'x': 482, 'y': 456, 'w': 40, 'h': 14, 'color': array([108.2962963 , 106.05925926, 107.65185185])}, {'text': 'with', 'x': 526, 'y': 456, 'w': 32, 'h': 14, 'color': array([113.62406015, 109.69924812, 109.47368421])}, {'text': 'efficient', 'x': 428, 'y': 473, 'w': 64, 'h': 17, 'color': array([111.5443038 , 106.70886076, 108.15611814])}, {'text': 'routes.', 'x': 492, 'y': 474, 'w': 54, 'h': 15, 'color': array([103.68072289,  98.22289157, 101.30120482])}, {'text': 'more', 'x': 385, 'y': 476, 'w': 40, 'h': 13, 'color': array([109.40145985, 104.9270073 , 106.55474453])}, {'text': 'package', 'x': 157, 'y': 492, 'w': 67, 'h': 19, 'color': array([73.3989011, 73.3989011, 73.3989011])}, {'text': 'Drop-off', 'x': 88, 'y': 493, 'w': 68, 'h': 16, 'color': array([74.87017995, 74.87017995, 74.87017995])}]\n",
      "[{'text': 'leverages', 'x': 428, 'y': 499, 'w': 75, 'h': 20, 'color': array([102.40392157,  98.75686275,  99.84705882])}]\n",
      "[{'text': 'Maps', 'x': 564, 'y': 499, 'w': 43, 'h': 19, 'color': array([102.26973684,  97.46710526,  98.375     ])}, {'text': 'NavaFleet', 'x': 346, 'y': 500, 'w': 82, 'h': 16, 'color': array([93.20427553, 89.48693587, 89.29216152])}]\n",
      "[{'text': 'for', 'x': 608, 'y': 500, 'w': 24, 'h': 14, 'color': array([110.27906977, 112.60465116, 121.45348837])}, {'text': 'Google', 'x': 506, 'y': 501, 'w': 55, 'h': 17, 'color': array([114.74235808, 108.13100437, 107.30131004])}, {'text': 'Charleston', 'x': 122, 'y': 512, 'w': 73, 'h': 16, 'color': array([71.31762065, 71.31762065, 71.31762065])}, {'text': '425', 'x': 96, 'y': 513, 'w': 25, 'h': 13, 'color': array([71.50226244, 71.50226244, 71.50226244])}]\n",
      "[{'text': 'Rd', 'x': 196, 'y': 513, 'w': 20, 'h': 13, 'color': array([72.0960452, 72.0960452, 72.0960452])}]\n",
      "[{'text': 'visibility', 'x': 439, 'y': 516, 'w': 64, 'h': 23, 'color': array([106.87179487, 103.26923077, 107.0042735 ])}, {'text': 'precise', 'x': 344, 'y': 517, 'w': 56, 'h': 20, 'color': array([106.60846561, 103.13756614, 104.22751323])}, {'text': 'fleet', 'x': 402, 'y': 518, 'w': 36, 'h': 16, 'color': array([111.16216216, 108.87162162, 111.95945946])}]\n",
      "[{'text': 'operational', 'x': 536, 'y': 518, 'w': 88, 'h': 19, 'color': array([115.65306122, 110.89795918, 109.32069971])}, {'text': 'and', 'x': 504, 'y': 520, 'w': 29, 'h': 14, 'color': array([117.7398374 , 114.04065041, 115.17886179])}, {'text': 'efficiency.', 'x': 344, 'y': 535, 'w': 78, 'h': 22, 'color': array([115.12786885, 113.4852459 , 116.44590164])}]\n",
      "[{'text': 'user-friendly,', 'x': 446, 'y': 535, 'w': 101, 'h': 21, 'color': array([110.01329787, 107.84308511, 113.03989362])}, {'text': 'Its', 'x': 422, 'y': 538, 'w': 22, 'h': 15, 'color': array([107.76712329, 107.90410959, 110.5890411 ])}]\n",
      "[{'text': 'scalable', 'x': 549, 'y': 538, 'w': 61, 'h': 15, 'color': array([102.80382775,  98.5645933 ,  99.14832536])}, {'text': 'training.', 'x': 545, 'y': 555, 'w': 65, 'h': 22, 'color': array([121.85477178, 116.1659751 , 114.26141079])}, {'text': 'interface', 'x': 345, 'y': 557, 'w': 68, 'h': 16, 'color': array([108.91855204, 101.76470588, 101.29864253])}, {'text': 'requires', 'x': 414, 'y': 557, 'w': 64, 'h': 16, 'color': array([116.18502203, 110.96475771, 110.86343612])}, {'text': 'minima', 'x': 481, 'y': 557, 'w': 57, 'h': 16, 'color': array([113.42929293, 111.55050505, 112.26767677])}, {'text': 'Customize', 'x': 345, 'y': 576, 'w': 81, 'h': 17, 'color': array([111.9       , 104.38846154, 104.15769231])}, {'text': 'alerts,', 'x': 427, 'y': 576, 'w': 49, 'h': 17, 'color': array([115.32738095, 111.98214286, 112.53571429])}]\n",
      "[{'text': 'and', 'x': 541, 'y': 576, 'w': 29, 'h': 16, 'color': array([98.92307692, 95.74725275, 98.43956044])}, {'text': 'reports,', 'x': 477, 'y': 577, 'w': 61, 'h': 16, 'color': array([112.36453202, 108.33990148, 109.59605911])}, {'text': 'operations.', 'x': 527, 'y': 594, 'w': 84, 'h': 20, 'color': array([113.2516129 , 109.06774194, 108.62903226])}, {'text': 'dashboards', 'x': 345, 'y': 596, 'w': 90, 'h': 17, 'color': array([109.1085044 , 103.07331378, 104.31671554])}]\n",
      "[{'text': 'suit', 'x': 457, 'y': 596, 'w': 29, 'h': 16, 'color': array([115.9009009 , 113.3963964 , 116.37837838])}, {'text': 'to', 'x': 437, 'y': 597, 'w': 17, 'h': 13, 'color': array([108.21818182, 106.94545455, 108.41818182])}]\n",
      "[{'text': 'your', 'x': 488, 'y': 598, 'w': 37, 'h': 16, 'color': array([116.70967742, 111.32258065, 109.61290323])}, {'text': 'reducing', 'x': 344, 'y': 612, 'w': 70, 'h': 23, 'color': array([111.67175573, 109.54580153, 113.80152672])}]\n",
      "[{'text': 'safety,', 'x': 541, 'y': 612, 'w': 54, 'h': 23, 'color': array([110.12105263, 106.98947368, 108.75789474])}, {'text': 'costs,', 'x': 415, 'y': 614, 'w': 45, 'h': 18, 'color': array([114.4137931 , 107.99310345, 106.83448276])}, {'text': 'improving', 'x': 462, 'y': 614, 'w': 77, 'h': 20, 'color': array([102.6124031 ,  99.03488372, 100.61627907])}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from basenet.vgg16_bn import vgg16_bn, init_weights\n",
    "import imgproc\n",
    "import craft_utils\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch+mid_ch, mid_ch, kernel_size=1),\n",
    "            nn.BatchNorm2d(mid_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class CRAFT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRAFT, self).__init__()\n",
    "        self.basenet = vgg16_bn(pretrained=False, freeze=False)\n",
    "        self.upconv1 = double_conv(1024, 512, 256)\n",
    "        self.upconv2 = double_conv(512, 256, 128)\n",
    "        self.upconv3 = double_conv(256, 128, 64)\n",
    "        self.upconv4 = double_conv(128, 64, 32)\n",
    "        self.conv_cls = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 2, kernel_size=1)\n",
    "        )\n",
    "        init_weights(self.upconv1.modules())\n",
    "        init_weights(self.upconv2.modules())\n",
    "        init_weights(self.upconv3.modules())\n",
    "        init_weights(self.upconv4.modules())\n",
    "        init_weights(self.conv_cls.modules())\n",
    "    def forward(self, x):\n",
    "        sources = self.basenet(x)\n",
    "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
    "        y = self.upconv1(y)\n",
    "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[2]], dim=1)\n",
    "        y = self.upconv2(y)\n",
    "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[3]], dim=1)\n",
    "        y = self.upconv3(y)\n",
    "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
    "        y = torch.cat([y, sources[4]], dim=1)\n",
    "        feature = self.upconv4(y)\n",
    "        y = self.conv_cls(feature)\n",
    "        return y.permute(0,2,3,1), feature\n",
    "\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = torch.load(weight_path, map_location='cpu')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] if k.startswith(\"module.\") else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "def get_text_color(roi):\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(roi_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    fg_color = np.mean(roi[binary == 0], axis=0)\n",
    "    return fg_color\n",
    "\n",
    "def merge_words_into_sentences(words, img_width, img_height):\n",
    "    words = sorted(words, key=lambda w: (w[\"y\"], w[\"x\"]))\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    threshold_x = 0.03 * img_width\n",
    "    threshold_y = 0.03 * img_height\n",
    "    for i in range(len(words)):\n",
    "        if i == 0:\n",
    "            current_sentence.append(words[i])\n",
    "            continue\n",
    "        prev_word = words[i - 1]\n",
    "        current_word = words[i]\n",
    "        x_gap = current_word[\"x\"] - (prev_word[\"x\"] + prev_word[\"w\"])\n",
    "        y_diff = abs(current_word[\"y\"] - prev_word[\"y\"])\n",
    "        color_diff = np.linalg.norm(current_word[\"color\"] - prev_word[\"color\"])\n",
    "        if x_gap < threshold_x and y_diff < threshold_y:\n",
    "            current_sentence.append(current_word)\n",
    "        else:\n",
    "            sentences.append(current_sentence)\n",
    "            for a in current_sentence:\n",
    "                print(a['text'])\n",
    "            current_sentence = [current_word]\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    model = CRAFT()\n",
    "    load_weights(model, \"craft_mlt_25k.pth\")\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    image = cv2.imread(\"img_test_ocr.png\")\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
    "    ratio_h = ratio_w = 1/target_ratio\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2,0,1).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(x)\n",
    "    score_text = output[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = output[0,:,:,1].cpu().data.numpy()\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, 0.7, 0.4, 0.4, False)\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    words = []\n",
    "    for box in boxes:\n",
    "        x_min, y_min = int(min(box, key=lambda p: p[0])[0]), int(min(box, key=lambda p: p[1])[1])\n",
    "        x_max, y_max = int(max(box, key=lambda p: p[0])[0]), int(max(box, key=lambda p: p[1])[1])\n",
    "        roi = image[y_min:y_max, x_min:x_max]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if text:\n",
    "            color = get_text_color(roi)\n",
    "            words.append({\"text\": text, \"x\": x_min, \"y\": y_min, \"w\": x_max-x_min, \"h\": y_max-y_min, \"color\": color})\n",
    "    sentences = merge_words_into_sentences(words, image.shape[1], image.shape[0])\n",
    "    img_out = image.copy()\n",
    "    for sentence in sentences:\n",
    "        x_min = min(word[\"x\"] for word in sentence)\n",
    "        y_min = min(word[\"y\"] for word in sentence)\n",
    "        x_max = max(word[\"x\"] + word[\"w\"] for word in sentence)\n",
    "        y_max = max(word[\"y\"] + word[\"h\"] for word in sentence)\n",
    "        text = \" \".join(word[\"text\"] for word in sentence)\n",
    "        cv2.rectangle(img_out, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "    cv2.imwrite(\"result.jpg\", img_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919 4\n",
      "\n",
      "? 0.2 mi\n",
      "\n",
      "Then 4 Park Ave S\n",
      "\n",
      "3\n",
      "\n",
      "3 minutes\n",
      "\n",
      "0.8 mi- 8:52 PM\n",
      "\n",
      "Drop-off package\n",
      "\n",
      "Charleston Rd\n",
      "\n",
      "| > WadisoMPAVERaNZRi\n",
      "sony ved!\n",
      "\n",
      "wed\n",
      "\n",
      "Built for all delivery fleets. :\n",
      "\n",
      "Whether you manage a small fleet of\n",
      "delivery vehicles or a large network of\n",
      "drivers, our NavaFLEET Solution scales to\n",
      "your needs.\n",
      "\n",
      "@ Track your fleet in real-time.\n",
      "See exact locations and get\n",
      "minute-by-minute updates with\n",
      "Google Maps.\n",
      "\n",
      "@ Set boundaries and get alerts.\n",
      "\n",
      "Receive notifications for\n",
      "\n",
      "unauthorized movements,\n",
      "\n",
      "route deviations, and more.\n",
      "\n",
      "9\n",
      "\n",
      "Analyze driver behavior.\n",
      "Monitor speed, braking, and\n",
      "idling to improve safety and\n",
      "performance.\n",
      "\n",
      "id Optimize routes and save\n",
      "fuel. Reduce costs with smarter,\n",
      "more efficient routes.\n",
      "\n",
      "NavaFleet leverages Google Maps for\n",
      "precise fleet visibility and operational\n",
      "efficiency. Its user-friendly, scalable\n",
      "interface requires minimal training.\n",
      "Customize alerts, reports, and\n",
      "dashboards to suit your operations—\n",
      "reducing costs, improving safety, and\n",
      "enhancing delivery efficiency.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Đọc ảnh\n",
    "image = cv2.imread(\"img_test_ocr.png\")\n",
    "\n",
    "# Chuyển ảnh thành văn bản\n",
    "text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
